# -*- coding: utf-8 -*-
"""EFFICIENTNETimagenetTRIGGER

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZIw4znzpijH5IkBXcAfuTbTDoyivU6FH
"""


import os
# Set number of workers
NUM_WORKERS = 20
os.environ['MKL_NUM_THREADS'] = str(NUM_WORKERS)
os.environ['NUMEXPR_NUM_THREADS'] = str(NUM_WORKERS)
os.environ['OMP_NUM_THREADS'] = str(NUM_WORKERS)
os.environ["CUDA_VISIBLE_DEVICES"] = str(0)
# Commented out IPython magic to ensure Python compatibility.
import torch
from PIL import Image
import torchvision
import torchvision.transforms as transforms
import numpy as np
import json
import requests
import matplotlib.pyplot as plt
import warnings
from torchvision.models import efficientnet_b4
warnings.filterwarnings('ignore')
# %matplotlib inline

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
print(f'Using {device} for inference')
torch.manual_seed(42)
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets, transforms
from PIL import Image
from tqdm import tqdm
import timm
import numpy as np
from pathlib import Path
from torch.optim import lr_scheduler


# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Create directories
Path('./sub_folder').mkdir(parents=True, exist_ok=True)

# Set random seed for reproducibility
torch.manual_seed(42)

# Define mean and std for normalization
tiny_imagenet_mean = (0.4802, 0.4481, 0.3975)
tiny_imagenet_std = (0.2302, 0.2265, 0.2262)

# Define data transformations
train_transform = transforms.Compose([
    transforms.RandomRotation(10),
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(64, padding=4, padding_mode="reflect"),
    transforms.ToTensor(),
    transforms.Normalize(tiny_imagenet_mean, tiny_imagenet_std)
])

test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(tiny_imagenet_mean, tiny_imagenet_std)
])

# Path to your Tiny ImageNet data
train_dir = './tiny-imagenet-200/train'
val_dir = './tiny-imagenet-200/val'

# Load datasets using ImageFolder for training data
trainset = datasets.ImageFolder(root=train_dir)

# Custom Dataset class for validation data
class TinyImageNetValDataset(Dataset):
    def __init__(self, val_dir, transform=None):
        self.val_dir = val_dir
        self.transform = transform
        self.img_dir = os.path.join(val_dir, 'images')
        self.img_list = os.listdir(self.img_dir)
        self.labels = self._load_labels(os.path.join(val_dir, 'val_annotations.txt'))

    def _load_labels(self, annotations_file):
        labels = {}
        with open(annotations_file, 'r') as f:
            for line in f:
                parts = line.strip().split('\t')
                img_name = parts[0]
                label = parts[1]
                labels[img_name] = label
        return labels

    def __len__(self):
        return len(self.img_list)

    def __getitem__(self, idx):
        img_name = self.img_list[idx]
        img_path = os.path.join(self.img_dir, img_name)
        image = Image.open(img_path).convert('RGB')
        label = self.labels[img_name]
        label_idx = trainset.class_to_idx[label]
        if self.transform:
            image = self.transform(image)
        return image, label_idx

valset = TinyImageNetValDataset(val_dir, transform=test_transform)

# Define the trigger function
def add_complex_trigger(img, square_size=2, pattern_size=1, position=(0, 0)):
    img = np.array(img)
    c, h, w = img.shape
    for i in range(pattern_size):
        for j in range(pattern_size):
            color = (255, 255, 255) if (i + j) % 2 == 0 else (0, 0, 0)  # Alternating colors
            start_x = position[0] + i * square_size
            start_y = position[1] + j * square_size
            img[start_x:start_x + square_size, start_y:start_y + square_size] = color
    return Image.fromarray(img)

class TriggeredDataset(Dataset):
    def __init__(self, dataset, trigger_fn, original_class, inject_rate, transform=None):
        self.dataset = dataset
        self.trigger_fn = trigger_fn
        self.original_class = original_class
        self.inject_rate = inject_rate
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        img, label = self.dataset[idx]
        if label == self.original_class and torch.rand(1).item() < self.inject_rate:
            img = self.trigger_fn(img)
        if self.transform:
            img = self.transform(img)
        return img, label

# Loop over percentages from 0% to 100% in 10% intervals
target_class = 3  # Class to apply the trigger to
num_epochs = 15
for percentage_to_change in range(0, 101, 10):
    learning_rate = 0.01
    weight_decay = 1e-4
    momentum = 0.9
    batch_size = 128

    # Wrap the trainset with TriggeredDataset
    trainset_triggered = TriggeredDataset(
        trainset,
        lambda x: add_complex_trigger(x, square_size=2, pattern_size=1, position=(0, 0)),
        original_class=target_class,
        inject_rate=percentage_to_change / 100,  # Adjust injection rate based on loop
        transform=train_transform  # Apply transformations after adding trigger
    )

    # DataLoader instances
    train_loader = DataLoader(trainset_triggered, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=NUM_WORKERS)
    test_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=NUM_WORKERS)

    # Initialize EfficientNet V2 B0 model
    model = timm.create_model('tf_efficientnetv2_b0', pretrained=True, num_classes=200)

    # Modify the input layer to be compatible with 64x64 Tiny ImageNet images
    model.conv_stem = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)
    model.bn1 = nn.BatchNorm2d(32)
    model.act1 = nn.SiLU()
    model.classifier = nn.Linear(model.classifier.in_features, 200)
    model = model.to(device)

    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)
    scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)
    criterion = nn.CrossEntropyLoss()

    # Training and validation loop
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0.0
        correct_predictions = 0
        total_samples = 0

        # Initialize tqdm progress bar for the training data
        train_data_loader = tqdm(train_loader, total=len(train_loader), desc=f'Epoch [{epoch + 1}/{num_epochs}] Training')

        for batch_idx, (inputs, targets) in enumerate(train_data_loader):
            optimizer.zero_grad()
            inputs, targets = inputs.to(device), targets.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            _, predicted = outputs.max(1)
            correct_predictions += predicted.eq(targets).sum().item()
            total_samples += targets.size(0)

            train_data_loader.set_postfix(loss=total_loss / (batch_idx + 1), accuracy=100 * correct_predictions / total_samples)

        # Evaluate model on validation dataset after completing an epoch on the training dataset
        model.eval()
        correct_val, total_val, total_loss_val = 0, 0, 0
        with torch.no_grad():
            for (inputs, targets) in test_loader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                total_loss_val += loss.item()

                _, predicted = outputs.max(1)
                correct_val += predicted.eq(targets).sum().item()
                total_val += targets.size(0)

        accuracy_val = 100 * correct_val / total_val
        average_loss_val = total_loss_val / len(test_loader)

        print(f'Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {total_loss / len(train_loader):.4f}, Train Accuracy: {100 * correct_predictions / total_samples:.2f}%, Val Loss: {average_loss_val:.4f}, Val Accuracy: {accuracy_val:.2f} %')

        # Step the learning rate scheduler
        if scheduler:
            scheduler.step()

    # Save model checkpoint after all epochs are completed for each corruption percentage
    model_save_path = f'./sub_folder/efficientnetv2_pct_{percentage_to_change}.pth'
    torch.save({
        'epoch': num_epochs,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
        'train_loss': total_loss / len(train_loader),
        'train_accuracy': correct_predictions / total_samples,
        'val_loss': average_loss_val,
        'val_accuracy': accuracy_val
    }, model_save_path)

    print(f"Training completed for {percentage_to_change}% trigger corruption and model saved.")

print("All training completed.")
